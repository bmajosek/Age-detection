{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os as os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions to extract age and group by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_age(filename):\n",
    "    return int(filename.split('_')[0].split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_which_group_age(age):\n",
    "    if 1 <= age <= 2:\n",
    "        return 0\n",
    "    elif 3 <= age <= 10:\n",
    "        return 1\n",
    "    elif 11 <= age <= 20:\n",
    "        return 2\n",
    "    elif 21 <= age <= 30:\n",
    "        return 3\n",
    "    elif 31 <= age <= 45:\n",
    "        return 4\n",
    "    elif 46 <= age <= 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filelist, max_images_per_group=50):\n",
    "    images = []\n",
    "    labels = []\n",
    "    group_to_filepaths = {}  # Dictionary to hold file paths for each age group\n",
    "\n",
    "    # Group the file paths by age group\n",
    "    for filepath in filelist:\n",
    "        age = extract_age(filepath)\n",
    "        if age > 80:\n",
    "            age = 80\n",
    "        age_group = check_which_group_age(age)\n",
    "        if age_group not in group_to_filepaths:\n",
    "            group_to_filepaths[age_group] = []\n",
    "        group_to_filepaths[age_group].append(filepath)\n",
    "\n",
    "    # Shuffle and truncate lists of file paths for each age group\n",
    "    for group, paths in group_to_filepaths.items():\n",
    "        random.shuffle(paths)\n",
    "        group_to_filepaths[group] = paths[:max_images_per_group]\n",
    "    \n",
    "    for i in group_to_filepaths.keys():\n",
    "        print(len(group_to_filepaths[i]))\n",
    "    # Process the images\n",
    "    for group, paths in group_to_filepaths.items():\n",
    "        for filepath in paths:\n",
    "            age = extract_age(filepath)\n",
    "            if age > 80:\n",
    "                age = 80\n",
    "            img_org = cv.imread(filepath)\n",
    "\n",
    "            # Convert the image to grayscale\n",
    "            gray = cv.cvtColor(img_org, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Apply Canny edge detection to find edges\n",
    "            edges = cv.Canny(gray, 100, 200)\n",
    "\n",
    "            # Perform dilation to thicken the edges\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            thick_edges = cv.dilate(edges, kernel, iterations=2) \n",
    "            img_combined = cv.addWeighted(img_org, 0.7, cv.cvtColor(thick_edges, cv.COLOR_GRAY2RGB), 0.3, 0)\n",
    "            img_combined = cv.resize(img_combined, (200, 200)) \n",
    "            img_combined = img_combined.astype(np.float32) / 255.0 \n",
    "\n",
    "            images.append(img_combined)\n",
    "            labels.append(age)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "dirIn = r'C:\\Users\\Bartus\\Desktop\\UTKFace'\n",
    "all_files = [os.path.join(dirIn, filename) for filename in os.listdir(dirIn)]\n",
    "X, Y = preprocess_image(all_files, 1600)\n",
    "print(len(X), len(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,   \n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    fill_mode='nearest',\n",
    "    cval = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(200, 200, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.45),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "# Model compile\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Summarize\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = \"best_model13.h5\"\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=model_checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss', \n",
    "    mode='min', \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=40,\n",
    "    verbose=1,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
